{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_data, load_config, write_to_file, one_hot_encoding\n",
    "\n",
    "# Load configuration\n",
    "config = load_config('./config.yaml')\n",
    "\n",
    "# Load the data and reshape from (32 x 32) to (1024 x 1)\n",
    "x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = np.eye(len(y_train), 10)[y_train]\n",
    "y_test = np.eye(len(y_test), 10)[y_test]\n",
    "\n",
    "x_train = np.array([image.reshape((1024)) for image in x_train], dtype='float')\n",
    "x_test = np.array([image.reshape((1024)) for image in x_test], dtype='float')\n",
    "\n",
    "# Create validation set out of training data.\n",
    "num = int(len(x_train) * 0.8)\n",
    "[x_train, x_val]= np.split(x_train, [num])\n",
    "[y_train, y_val] = np.split(y_train, [num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature mean and standard deviation for x_train, and use them to\n",
    "# Z score x_train, X_val and X_test\n",
    "def z_score_train_test(train, val, test):\n",
    "    train_T = train.T\n",
    "    val_T = val.T\n",
    "    test_T = test.T\n",
    "    for i in range(len(train_T)):\n",
    "        mean = np.mean(train_T[i])\n",
    "        SD = np.std(train_T[i])\n",
    "        train_T[i] = (train_T[i] - mean) / SD\n",
    "        val_T[i] = (val_T[i] - mean) / SD\n",
    "        test_T[i] = (test_T[i] - mean) / SD\n",
    "    return train_T.T, val_T.T, test_T.T\n",
    "\n",
    "# Z-scoring\n",
    "x_train, x_val, x_test = z_score_train_test(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "valid_acc = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet import *\n",
    "\n",
    "model = NeuralNetwork(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, t):\n",
    "    y = np.argmax(y, axis=1)\n",
    "    t = np.argmax(t, axis=1)\n",
    "    res = [y_hat == t_hat for y_hat, t_hat in zip(y, t)]\n",
    "    return np.sum(res) / len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 2.5133147001142744 Accuracy 0.1291973791973792\n",
      "Epoch 1 Loss 2.452964720109597 Accuracy 0.14182364182364182\n",
      "Epoch 2 Loss 2.4196881822051455 Accuracy 0.14905814905814907\n",
      "Epoch 3 Loss 2.400072424734549 Accuracy 0.15226590226590225\n",
      "Epoch 4 Loss 2.38648416030877 Accuracy 0.15779415779415779\n",
      "Epoch 5 Loss 2.371269238193037 Accuracy 0.15124215124215123\n",
      "Epoch 6 Loss 2.3585589122797375 Accuracy 0.1558149058149058\n",
      "Epoch 7 Loss 2.3510655346001186 Accuracy 0.1650969150969151\n",
      "Epoch 8 Loss 2.345583625894367 Accuracy 0.1622986622986623\n",
      "Epoch 9 Loss 2.340652850851343 Accuracy 0.16223041223041224\n",
      "Epoch 10 Loss 2.33269951182659 Accuracy 0.16755391755391755\n",
      "Epoch 11 Loss 2.327833777502246 Accuracy 0.16325416325416325\n",
      "Epoch 12 Loss 2.3252229227625203 Accuracy 0.16257166257166258\n",
      "Epoch 13 Loss 2.3221006480011823 Accuracy 0.16516516516516516\n",
      "Epoch 14 Loss 2.316696313790157 Accuracy 0.17553917553917553\n",
      "Epoch 15 Loss 2.3119441608075504 Accuracy 0.1788151788151788\n",
      "Epoch 16 Loss 2.307439316017384 Accuracy 0.17895167895167896\n",
      "Epoch 17 Loss 2.305935367997145 Accuracy 0.18065793065793065\n",
      "Epoch 18 Loss 2.306810573754887 Accuracy 0.18297843297843297\n",
      "Epoch 19 Loss 2.3042291429703896 Accuracy 0.18284193284193284\n",
      "Epoch 20 Loss 2.296790599069909 Accuracy 0.18488943488943488\n",
      "Epoch 21 Loss 2.2953210849801238 Accuracy 0.1807944307944308\n",
      "Epoch 22 Loss 2.300133449570858 Accuracy 0.18209118209118208\n",
      "Epoch 23 Loss 2.290433511021302 Accuracy 0.17424242424242425\n",
      "Epoch 24 Loss 2.290997020956435 Accuracy 0.16987441987441987\n",
      "Epoch 25 Loss 2.2877679705542535 Accuracy 0.1835926835926836\n",
      "Epoch 26 Loss 2.285711103895584 Accuracy 0.19103194103194104\n",
      "Epoch 27 Loss 2.282723532959368 Accuracy 0.191987441987442\n",
      "Epoch 28 Loss 2.2810128652716406 Accuracy 0.18857493857493857\n",
      "Epoch 29 Loss 2.2782189369816317 Accuracy 0.1904176904176904\n",
      "Epoch 30 Loss 2.2763590856478455 Accuracy 0.19150969150969152\n",
      "Epoch 31 Loss 2.271347725663104 Accuracy 0.19464919464919464\n",
      "Epoch 32 Loss 2.2709156674540862 Accuracy 0.1956729456729457\n",
      "Epoch 33 Loss 2.271039000523432 Accuracy 0.19034944034944035\n",
      "Epoch 34 Loss 2.2715371621251697 Accuracy 0.18543543543543545\n",
      "Epoch 35 Loss 2.2693995052167604 Accuracy 0.19314769314769314\n",
      "Epoch 36 Loss 2.2680991876505248 Accuracy 0.19696969696969696\n",
      "Epoch 37 Loss 2.2705912974136093 Accuracy 0.19580944580944581\n",
      "Epoch 38 Loss 2.2645098995034694 Accuracy 0.19990444990444992\n",
      "Epoch 39 Loss 2.2621368039899723 Accuracy 0.2007234507234507\n",
      "Epoch 40 Loss 2.2638520279378973 Accuracy 0.20782145782145783\n",
      "Epoch 41 Loss 2.2582039482152725 Accuracy 0.20113295113295113\n",
      "Epoch 42 Loss 2.2585858413726108 Accuracy 0.20256620256620256\n",
      "Epoch 43 Loss 2.2560807220319425 Accuracy 0.19894894894894896\n",
      "Epoch 44 Loss 2.259369351123742 Accuracy 0.20277095277095278\n",
      "Epoch 45 Loss 2.2555811288776058 Accuracy 0.20618345618345618\n",
      "Epoch 46 Loss 2.248594278264035 Accuracy 0.20406770406770408\n",
      "Epoch 47 Loss 2.2516323513606036 Accuracy 0.19847119847119848\n",
      "Epoch 48 Loss 2.247285806193314 Accuracy 0.20686595686595688\n",
      "Epoch 49 Loss 2.2431657501945685 Accuracy 0.2110974610974611\n",
      "Epoch 50 Loss 2.2440246475807704 Accuracy 0.20768495768495768\n",
      "Epoch 51 Loss 2.2445312993905144 Accuracy 0.2082992082992083\n",
      "Epoch 52 Loss 2.244174975702204 Accuracy 0.2085039585039585\n",
      "Epoch 53 Loss 2.240594961753163 Accuracy 0.21519246519246518\n",
      "Epoch 54 Loss 2.2383341372992622 Accuracy 0.21485121485121486\n",
      "Epoch 55 Loss 2.236903423756547 Accuracy 0.21096096096096095\n",
      "Epoch 56 Loss 2.2383881131651675 Accuracy 0.21102921102921102\n",
      "Epoch 57 Loss 2.234904248829541 Accuracy 0.20652470652470653\n",
      "Epoch 58 Loss 2.2326116778524683 Accuracy 0.214987714987715\n",
      "Epoch 59 Loss 2.2317885330662652 Accuracy 0.21683046683046683\n",
      "Epoch 60 Loss 2.231321191510891 Accuracy 0.21519246519246518\n",
      "Epoch 61 Loss 2.2326371805310705 Accuracy 0.21573846573846575\n",
      "Epoch 62 Loss 2.2319027774716327 Accuracy 0.21164346164346165\n",
      "Epoch 63 Loss 2.2275124976627474 Accuracy 0.2186049686049686\n",
      "Epoch 64 Loss 2.224995974214962 Accuracy 0.22522522522522523\n",
      "Epoch 65 Loss 2.2252701829544823 Accuracy 0.2265902265902266\n",
      "Epoch 66 Loss 2.2243979525169646 Accuracy 0.22515697515697516\n",
      "Epoch 67 Loss 2.2195605655021344 Accuracy 0.22583947583947583\n",
      "Epoch 68 Loss 2.2187764765787628 Accuracy 0.2263172263172263\n",
      "Epoch 69 Loss 2.2190721352183167 Accuracy 0.2287059787059787\n",
      "Epoch 70 Loss 2.2145625205100625 Accuracy 0.22815997815997816\n",
      "Epoch 71 Loss 2.215385632994749 Accuracy 0.22392847392847393\n",
      "Epoch 72 Loss 2.2143265087157853 Accuracy 0.22556647556647558\n",
      "Epoch 73 Loss 2.211509102141142 Accuracy 0.22904722904722905\n",
      "Epoch 74 Loss 2.213211130441586 Accuracy 0.22877422877422876\n",
      "Epoch 75 Loss 2.211948855182244 Accuracy 0.22925197925197927\n",
      "Epoch 76 Loss 2.2095284597089173 Accuracy 0.22966147966147965\n",
      "Epoch 77 Loss 2.2074985677060717 Accuracy 0.23437073437073436\n",
      "Epoch 78 Loss 2.209163275797888 Accuracy 0.22863772863772863\n",
      "Epoch 79 Loss 2.2066282306509284 Accuracy 0.23607698607698607\n",
      "Epoch 80 Loss 2.205549313309504 Accuracy 0.23832923832923833\n",
      "Epoch 81 Loss 2.2045515080077203 Accuracy 0.2424924924924925\n",
      "Epoch 82 Loss 2.2044392635832804 Accuracy 0.23382473382473382\n",
      "Epoch 83 Loss 2.2011478701133362 Accuracy 0.23286923286923286\n",
      "Epoch 84 Loss 2.204211309654696 Accuracy 0.23594048594048594\n",
      "Epoch 85 Loss 2.200920152605716 Accuracy 0.234984984984985\n",
      "Epoch 86 Loss 2.1981429862158026 Accuracy 0.23491673491673493\n",
      "Epoch 87 Loss 2.2010003818395 Accuracy 0.22863772863772863\n",
      "Epoch 88 Loss 2.196488249357615 Accuracy 0.23245973245973245\n",
      "Epoch 89 Loss 2.193138606492748 Accuracy 0.23641823641823642\n",
      "Epoch 90 Loss 2.19005621791102 Accuracy 0.23785148785148785\n",
      "Epoch 91 Loss 2.190567599513902 Accuracy 0.23832923832923833\n",
      "Epoch 92 Loss 2.190675160994911 Accuracy 0.23675948675948677\n",
      "Epoch 93 Loss 2.189818676893627 Accuracy 0.2394212394212394\n",
      "Epoch 94 Loss 2.1903559560999546 Accuracy 0.2377832377832378\n",
      "Epoch 95 Loss 2.189128046335882 Accuracy 0.23518973518973518\n",
      "Epoch 96 Loss 2.18705528276443 Accuracy 0.23198198198198197\n",
      "Epoch 97 Loss 2.1817822598245886 Accuracy 0.2390799890799891\n",
      "Epoch 98 Loss 2.1831560993886754 Accuracy 0.2452907452907453\n",
      "Epoch 99 Loss 2.182840758189532 Accuracy 0.24153699153699154\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "for i in range(config['epochs']): \n",
    "    # Randomize the order of the indices into the training set\n",
    "    shuffled_indices = np.random.permutation(len(x_train))\n",
    "    x_train = x_train[shuffled_indices]\n",
    "    y_train = y_train[shuffled_indices]\n",
    "    for j in range(0, len(x_train), config['batch_size']):\n",
    "        if (j + config['batch_size'] < len(x_train)):\n",
    "            batch_x = x_train[[j, j + config['batch_size']]]\n",
    "            batch_y = y_train[[j, j + config['batch_size']]]\n",
    "        else:\n",
    "            batch_x = x_train[[j, len(x_train) - 1]]\n",
    "            batch_y = y_train[[j, len(x_train) - 1]]\n",
    "        y, loss = model(x=batch_x, targets=batch_y)\n",
    "        model.backward()\n",
    "        \n",
    "    y, loss = model.forward(x_val, y_val)\n",
    "    acc = accuracy(y, y_val)\n",
    "    print('Epoch', i, 'Loss', loss, 'Accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(config=config)\n",
    "\n",
    "# Choose one output bias weight'\n",
    "epsilon = 1e-2\n",
    "model.layers[2].b[8] += epsilon\n",
    "model.forward(x_val)\n",
    "e_w_plus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
